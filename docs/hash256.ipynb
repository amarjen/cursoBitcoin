{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dca7db9abbc2dbc5e001c7a890d55ec91366dfd7b02b897fc8a2a0e4744f8d35'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha256(b'UN MURCIELAGO VELOZ').hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72e32188f9eeefc57ee94e84071c2867ef4a14538e4fed1579ce89d6ce4112ed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha256(b'UN MURCIELAGO VELOY').hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txs = [b'a',b'b',b'c',b'd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "txshashes = [hashlib.sha256(tx).hexdigest() for tx in txs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb',\n",
       "  '3e23e8160039594a33894f6564e1b1348bbd7a0088d42c4acb73eeaed59c009d'],\n",
       " ['2e7d2c03a9507ae265ecf5b5356885a53393a2029d241394997265a1a25aefc6',\n",
       "  '18ac3e7343f016890c510e93f935261169d9e3f565436429830faf0934f4f8e4']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[txshashes[s] for s in [slice(i,i+2) for i in range(0,4,2)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256\n",
    "\n",
    "\n",
    "class MerkleNode:\n",
    "    \"\"\"\n",
    "    Stores the hash and the parent.\n",
    "    \"\"\"\n",
    "    def __init__(self, hash):\n",
    "        self.hash = hash\n",
    "        self.parent = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.leaves = None\n",
    "\n",
    "\n",
    "class MerkleTree:\n",
    "    \"\"\"\n",
    "    Stores the leaves and the root hash of the tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_chunks):\n",
    "        leaves = []\n",
    "\n",
    "        for chunk in data_chunks:\n",
    "            node = MerkleNode(self.compute_hash(chunk))\n",
    "            leaves.append(node)\n",
    "\n",
    "        self.leaves = leaves\n",
    "        self.root = self.build_merkle_tree(leaves)\n",
    "        \n",
    "\n",
    "    def build_merkle_tree(self, leaves):\n",
    "        \"\"\"\n",
    "        Builds the Merkle tree from a list of leaves. In case of an odd number of leaves, the last leaf is duplicated.\n",
    "        \"\"\"\n",
    "        num_leaves = len(leaves)\n",
    "        if num_leaves == 1:\n",
    "            return leaves[0]\n",
    "\n",
    "        parents = []\n",
    "\n",
    "        i = 0\n",
    "        while i < num_leaves:\n",
    "            left_child = leaves[i]\n",
    "            right_child = leaves[i + 1] if i + 1 < num_leaves else left_child\n",
    "\n",
    "            parents.append(self.create_parent(left_child, right_child))\n",
    "\n",
    "            i += 2\n",
    "\n",
    "        return self.build_merkle_tree(parents)\n",
    "\n",
    "    def create_parent(self, left_child, right_child):\n",
    "        parent = MerkleNode(\n",
    "            self.compute_hash(left_child.hash + right_child.hash))\n",
    "        \n",
    "        parent.left_child, parent.right_child = left_child, right_child\n",
    "        left_child.parent, right_child.parent = parent, parent\n",
    "\n",
    "        return parent\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_hash(data):\n",
    "        data = data.encode('utf-8')\n",
    "        return sha256(data).hexdigest()\n",
    "    \n",
    "    def get_audit_trail(self, chunk_hash):\n",
    "        \"\"\"\n",
    "        Checks if the leaf exists, and returns the audit trail\n",
    "        in case it does.\n",
    "        \"\"\"\n",
    "        for leaf in self.leaves:\n",
    "            if leaf.hash == chunk_hash:\n",
    "        #        print(\"Leaf exists\")\n",
    "                return self.generate_audit_trail(leaf)\n",
    "            \n",
    "        return False\n",
    "        \n",
    "        #return [self.generate_audit_trail(leaf) for leaf in self.leaves if leaf.hash == chunk_hash]\n",
    "\n",
    "    def generate_audit_trail(self, merkle_node, trail=[]):\n",
    "        \"\"\"\n",
    "        Generates the audit trail in a bottom-up fashion\n",
    "        \"\"\"\n",
    "        if merkle_node == self.root:\n",
    "            trail.append(merkle_node.hash)\n",
    "            return trail\n",
    "\n",
    "        # check if the merkle_node is the left child or the right child\n",
    "        is_left = merkle_node.parent.left_child == merkle_node\n",
    "        if is_left:\n",
    "            # since the current node is left child, right child is\n",
    "            # needed for the audit trail. We'll need this info later\n",
    "            # for audit proof.\n",
    "            trail.append((merkle_node.parent.right_child.hash, not is_left))\n",
    "            return self.generate_audit_trail(merkle_node.parent, trail)\n",
    "        \n",
    "        else:\n",
    "            trail.append((merkle_node.parent.left_child.hash, is_left))\n",
    "            return self.generate_audit_trail(merkle_node.parent, trail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "txs = ['a', 'b', 'c', 'd']\n",
    "merkle_tree = MerkleTree(txs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58c89d709329eb37285837b042ab6ff72c7c8f74de0446b091b6a0131c102cfd\n"
     ]
    }
   ],
   "source": [
    "print(merkle_tree.root.hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_hash = MerkleTree.compute_hash(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_trail = merkle_tree.get_audit_trail(chunk_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3e23e8160039594a33894f6564e1b1348bbd7a0088d42c4acb73eeaed59c009d', False),\n",
       " ('d3a0f1c792ccf7f1708d5422696263e35755a86917ea76ef9242bd4a8cf4891a', False),\n",
       " '58c89d709329eb37285837b042ab6ff72c7c8f74de0446b091b6a0131c102cfd',\n",
       " ('3e23e8160039594a33894f6564e1b1348bbd7a0088d42c4acb73eeaed59c009d', False),\n",
       " ('d3a0f1c792ccf7f1708d5422696263e35755a86917ea76ef9242bd4a8cf4891a', False),\n",
       " '58c89d709329eb37285837b042ab6ff72c7c8f74de0446b091b6a0131c102cfd']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_audit_trail(chunk_hash, audit_trail):\n",
    "    \"\"\"\n",
    "    Performs the audit-proof from the audit_trail received\n",
    "    from the trusted server.\n",
    "    \"\"\"\n",
    "    assert audit_trail is not False\n",
    "    proof_till_now = chunk_hash\n",
    "    for node in audit_trail[:-1]:\n",
    "        hash = node[0]\n",
    "        is_left = node[1]\n",
    "        if is_left:\n",
    "            # the order of hash concatenation depends on whether the\n",
    "            # the node is a left child or right child of its parent\n",
    "            proof_till_now = MerkleTree.compute_hash(hash + proof_till_now)\n",
    "        else:\n",
    "            proof_till_now = MerkleTree.compute_hash(proof_till_now + hash)\n",
    "        print(proof_till_now)\n",
    "    \n",
    "    # verifying the computed root hash against the actual root hash\n",
    "    return proof_till_now == audit_trail[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62af5c3cb8da3e4f25061e829ebeea5c7513c54949115b1acc225930a90154da\n",
      "58c89d709329eb37285837b042ab6ff72c7c8f74de0446b091b6a0131c102cfd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_audit_trail(chunk_hash, audit_trail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
